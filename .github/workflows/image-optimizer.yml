# æ–‡ä»¶è·¯å¾„: .github/workflows/image-optimizer.yml

name: 'ğŸ¤– Optimize Bundle Images with ShortPixel'

on:
  push:
    branches:
      - main
    paths:
      - 'content/**/*.jpg'
      - 'content/**/*.png'
      - 'content/**/*.jpeg'
  
  schedule:
    - cron: '0 0 * * *'
    
  workflow_dispatch:

jobs:
  build:
    name: Convert Images Job
    runs-on: ubuntu-latest
    
    permissions:
      contents: write
      
    if: github.event.pusher.name != 'GitHub Actions Bot' && github.event.pusher.name != 'github-actions[bot]'

    steps:
      - name: 'â¬‡ï¸ Checkout Code'
        uses: actions/checkout@v4

      - name: 'ğŸ”§ Install Dependencies'
        run: sudo apt-get update && sudo apt-get install -y imagemagick jq

      - name: 'ğŸ”„ Find Images to Process'
        id: find_files
        run: |
          echo "ğŸ” Finding images that need conversion..."
          FILE_LIST=$(
            find content -type f \( -iname "*.jpg" -o -iname "*.jpeg" -o -iname "*.png" \) | while read -r f; do
              if [ ! -f "${f%.*}.avif" ]; then
                echo "$f"
              fi
            done
          )
          UNCONVERTED_FILES=$(echo $FILE_LIST)
          if [ -n "$UNCONVERTED_FILES" ]; then
            echo "  - Found $(echo $UNCONVERTED_FILES | wc -w) unconverted images."
            echo "files_to_process=${UNCONVERTED_FILES}" >> $GITHUB_OUTPUT
          else
            echo "âœ… No images to process."
            echo "files_to_process=" >> $GITHUB_OUTPUT
          fi
          
      - name: 'ğŸš€ Process Images with ShortPixel and Smart Polling'
        if: steps.find_files.outputs.files_to_process != ''
        env:
          SHORTPIXEL_KEY: ${{ secrets.SHORTPIXEL_KEY }}
          FILES_TO_PROCESS: ${{ steps.find_files.outputs.files_to_process }}
          MAX_ATTEMPTS: 5
          POLL_INTERVAL_SECONDS: 30
        run: |
          PENDING_URLS_STRING=$(echo "$FILES_TO_PROCESS" | tr ' ' '\n' | jq -R . | jq -s 'map("https://raw.githubusercontent.com/${{ github.repository }}/${{ github.sha }}/" + .)')
          
          for attempt in $(seq 1 $MAX_ATTEMPTS); do
            if [ "$(echo "$PENDING_URLS_STRING" | jq 'length')" -eq 0 ]; then
                echo "ğŸ‰ All images processed successfully!"
                break
            fi

            echo -e "\n-=================================-\n-   ATTEMPT ${attempt} / ${MAX_ATTEMPTS}\n-   Processing $(echo "$PENDING_URLS_STRING" | jq 'length') images...\n-=================================-\n"

            # ä¿®æ”¹ JSON è½½è·ï¼Œä½¿ç”¨æ­£ç¡®çš„ AVIF è½¬æ¢å‚æ•°
            JSON_PAYLOAD=$(jq -n --arg key "$SHORTPIXEL_KEY" --argjson urls "$PENDING_URLS_STRING" '{
              key: $key, 
              plugin_version: "GHA45", 
              lossy: 2, 
              wait: 30, 
              convertto: "avif",
              urllist: $urls
            }')

            echo "ğŸ“ Calling ShortPixel API..."
            echo "ğŸ” Debug - Request payload:"
            echo "$JSON_PAYLOAD" | jq '.'
            
            API_RESPONSE=$(curl -s -X POST -H "Content-Type: application/json" -d "$JSON_PAYLOAD" https://api.shortpixel.com/v2/reducer.php)
            
            echo "âœ… API call successful. Analyzing results..."
            echo "ğŸ” Debug - Full API response:"
            echo "$API_RESPONSE" | jq '.'

            # æ£€æŸ¥ API å“åº”ä¸­çš„æ‰€æœ‰å¯èƒ½çš„ URL å­—æ®µ
            echo "ğŸ” Debug - Checking available URL fields in response:"
            echo "$API_RESPONSE" | jq -c '.[] | keys | map(select(test("URL"; "i")))'

            # 1. Process and download all TRULY successful images with AVIF Lossy URLs
            echo "$API_RESPONSE" | jq -c '.[] | select(.Status.Code == "2")' | while read -r item; do
              original_url=$(echo "$item" | jq -r .OriginalURL)
              original_path=$(echo "$original_url" | sed "s|https://raw.githubusercontent.com/${{ github.repository }}/${{ github.sha }}/||")
              
              # ä¸“é—¨æŸ¥æ‰¾ AVIFLossyURLï¼Œå› ä¸ºæˆ‘ä»¬è®¾ç½®äº† lossy: 2
              avif_url=$(echo "$item" | jq -r '.AVIFLossyURL // empty')
              
              echo "    - ğŸ” Debug: AVIFLossyURL = '$avif_url'"
              echo "    - ğŸ” Debug: Original path = '$original_path'"
              
              if [ -n "$avif_url" ] && [ "$avif_url" != "null" ] && [ "$avif_url" != "NA" ]; then
                dir_path=$(dirname "$original_path")
                base_name=$(basename "$original_path" | sed 's/\.[^.]*$//')
                avif_path="$dir_path/$base_name.avif"
                echo "    - âœ… Found AVIF Lossy URL: $avif_url"
                echo "    - ğŸ“¥ Downloading AVIF from: $avif_url"
                echo "    - ğŸ“ Saving AVIF to: $avif_path"
                
                curl -fsS --retry 3 -o "$avif_path" "$avif_url"
                if [ -s "$avif_path" ]; then
                    # æ£€æŸ¥ä¸‹è½½çš„æ–‡ä»¶å¤§å°
                    downloaded_size=$(stat -c%s "$avif_path" 2>/dev/null || stat -f%z "$avif_path" 2>/dev/null)
                    expected_size=$(echo "$item" | jq -r '.AVIFLossySize')
                    echo "    - ğŸ“Š Downloaded file size: $downloaded_size bytes"
                    echo "    - ğŸ“Š Expected AVIF size: $expected_size bytes"
                    
                    dimensions=$(identify -format "%wx%h" "$original_path")
                    yaml_file="$dir_path/.image_dimensions.yaml"
                    touch "$yaml_file"
                    grep -q "${base_name}:" "$yaml_file" && sed -i "s|${base_name}:.*|${base_name}: ${dimensions}|" "$yaml_file" || echo "${base_name}: ${dimensions}" >> "$yaml_file"
                    echo "    - âœ… AVIF saved successfully, removing original file: $original_path"
                    rm "$original_path"
                else
                    echo "    - âŒ AVIF download failed for '$original_path'. It will be retried."
                fi
              else
                echo "    - âš ï¸ AVIFLossyURL not available for '$original_path'"
                echo "    - ğŸ” Available fields: $(echo "$item" | jq -r 'keys | join(", ")')"
              fi
            done
            
            # 2. Log any other statuses for clarity.
            echo "$API_RESPONSE" | jq -c '.[] | select(.Status.Code != "2")' | while read -r item; do
              status_code=$(echo "$item" | jq -r .Status.Code)
              status_message=$(echo "$item" | jq -r .Status.Message)
              original_path=$(echo "$item" | jq -r .OriginalURL | sed "s|https://raw.githubusercontent.com/${{ github.repository }}/${{ github.sha }}/||")
              if [ "$status_code" == "1" ]; then
                echo "    - â³ IN PROGRESS: '$original_path' is still processing."
              else
                echo "    - âŒ ERROR ($status_code): Could not process '$original_path'. Reason: '$status_message'."
              fi
            done

            # 3. é‡æ–°å®šä¹‰å¾…å¤„ç†çš„ URL åˆ—è¡¨
            # åªæœ‰çŠ¶æ€ç ä¸æ˜¯ 2 æˆ–è€…æ²¡æœ‰æ‰¾åˆ° AVIFLossyURL çš„é¡¹ç›®æ‰éœ€è¦é‡è¯•
            NEXT_PENDING_URLS_STRING=$(echo "$API_RESPONSE" | jq '[.[] | select(.Status.Code != "2" or (.AVIFLossyURL == null or .AVIFLossyURL == "NA" or .AVIFLossyURL == "")) | .OriginalURL]')
            
            PENDING_URLS_STRING="$NEXT_PENDING_URLS_STRING"

            if [ "$(echo "$PENDING_URLS_STRING" | jq 'length')" -gt 0 ] && [ "$attempt" -lt "$MAX_ATTEMPTS" ]; then
                echo -e "\n\t... waiting ${POLL_INTERVAL_SECONDS} seconds before next attempt ...\n"
                sleep $POLL_INTERVAL_SECONDS
            fi
          done

          if [ "$(echo "$PENDING_URLS_STRING" | jq 'length')" -gt 0 ]; then
              echo "âš ï¸ WARNING: After ${MAX_ATTEMPTS} attempts, the following images could not be processed:"
              echo "$PENDING_URLS_STRING" | jq -r '.[]'
          fi

      - name: 'ğŸš€ Commit and Push Changes'
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: 'build(media): Convert bundle images to AVIF'
          commit_author: ${{ github.actor }} <${{ github.actor_id }}+${{ github.actor }}@users.noreply.github.com>
